---
title: VGG(2014)，3x3卷积的胜利
mathjax: true
date: 2019-10-11 19:43:53
tags:
categories:
- backbone网络
---



博客：[blog.shinelee.me](https://blog.shinelee.me/) | [博客园](https://www.cnblogs.com/shine-lee/) | [CSDN](https://blog.csdn.net/blogshinelee)



# 写在前面

VGG(2014)网络出自paper[《Very Deep Convolutional Networks for Large-Scale Image Recognition》](https://arxiv.org/abs/1409.1556)，为[ILSVRC2014](http://www.image-net.org/challenges/LSVRC/2014/results#clsloc) localization冠军和classification亚军方法（冠军为GoogLeNet），首次提交arXiv时间为2014年9月，后发表在ICLR2015，截止20191011引用量达27612。因为出自牛津大学Visual Geometry Group，所以网络被命名为VGG，根据层数不同，又分为VGG16、VGG19等。

![VGG citations](https://s2.ax1x.com/2019/10/11/uqaoAe.png)

论文的主要贡献：

- 探究了网络深度对性能的影响，通过叠加卷积层来**增加深度，性能变好**——“Our results yet again confirm the importance of depth in visual representations”。
- **只使用$3\times 3$的卷积核，通过多个$3 \times 3$卷积层叠加来获得与大卷积核相同的感受野**，同时引入更多的非线性，减少了参数。若有$C$个channel，3个$3\times 3$的卷积层参数量为$3(3^2C^2)=27C^2$，1个$7\times 7$卷积层的参数量为$7^2C^2=49C^2$，两者的感受野相同。



# 网络结构

文中列举了配置不同的5个网络，分别命名为A、A-LRN、B、C、D、E，网络结构及参数量如下图所示，

![VGG configurations](https://s2.ax1x.com/2019/10/14/KSVzw9.png)

这些网络配置的特点是：

- A-LRN与A相比，仅在第一个卷积层后加入LRN层，A和A-LRN含可学习参数的层数均为11层
- B比A多了2个$3 \times 3$卷积层，为13层
- C比B多了3个$1\times 1$卷积层，为16层
- D将C的3个$1\times 1$卷积层替换为$3\times 3$卷积层，仍为16层
- E在D的基础上又增加了3个$3\times 3$卷积层，为19层
- 每次maxpool后，feature map尺寸减半，紧随其后的卷积层会将feature map的数量加倍，64→128→256→512

B网络有个特点，每2个$3\times 3$卷积层一组，再接maxpool。实际上，在实验中还配置了另一个网络——将B的“each pair of $3\times 3$ conv”替换为1个$5\times 5$卷积层，其性能要比B差7%，所以paper认为**小卷积核深网络要比大卷积核浅网络好**。

paper中的实验均在上述网络中进行，下面具体看一下。



# multi-scale training and testing

在训练阶段，VGG的输入固定为$224\times 224$，对尺寸不同的图像需要先scale再crop到$224\times 224$，理论上只需要将图像最短的边scale到大于等于224即可进行crop，paper中设置了2种scale方式，第一种scale到256或384，第二种随机scale到$[256, 512]$之间——384恰好位于256和512的中间，做了对比实验。

测试阶段，不再进行crop操作，而是采用了[Overfeat](https://arxiv.org/abs/1312.6229)中的一个技巧，**将网络最后的3个全连接层在实现上转化成卷积层，以适应不同尺寸的输入**，这个技巧在paper中称之为**dense**。**全连接层的运算方式是输入向量与权重矩阵相乘，当权重矩阵的尺寸确定了，输入向量的长度就不可改变了，而卷积的运算方式是权重在输入上滑动内积，所以只需要输入的尺寸大于kernel的窗口即可。**具体地，如果输入恰好为$224\times 224$，经历过5次maxpool后，feature map尺寸变为$7 \times 7$，当输入尺寸大于224时，这个feature map将大于等于$7\times 7$。将3个全连接层依次转化为$7\times 7$卷积和2个$1\times 1$卷积，**这种转化并不改变权重，只是实现方式上的变化**，此时整个网络为**全卷积网络**。如果输入图像大于$224\times 224$，网络最后输出的class score map将大于$1000 \times 1$，为了得到固定长度为1000的class score vetor，只需将其进行spatially average(sum-pooled)，然后再softmax。更多可以参见[Converting Fully-Connected Layers to Convolutional Layers](http://cs231n.github.io/convolutional-networks/#convert)的解释。

预测阶段的multi scale，即将输入图像做不同scale，分别输入网络，对预测结果取平均。

下图分别为single scale和mutiple scale测试的结果，测试库为ILSVRC-2012 dataset，

![single test scale](https://s2.ax1x.com/2019/10/14/KSTrxU.png)

![multiple test scales](https://s2.ax1x.com/2019/10/14/KSTqZd.png)

上面的对比实验，可得出以下结论：

- **随着深度增加，性能变好**
- 与A相比，A-LRN性能没有改善，**LRN用途不大**
- **无论是training还是testing，multiple scale均能改善性能**，两者结合使用效果更佳
- 在当前数据集和网络结构配置上，VGG16（D）和VGG19（E）性能基本一样，接近饱和

对于multi scale对性能的改善，想来也是合理的，因为图像中目标的尺寸并不确定，有大有小，在训练阶段通过scale jittering来增广数据，可让网络在一定程度上cover这种变化，而在预测阶段，multi scale可以看成在输入数据上做的集成学习，亦是提升性能的常规操作。



# 其他有意思的点

论文中还有一些其他有意思的点，简单总结如下，

- 为了网络能正常收敛，权重的初始化很重要，原来是先训练浅层网络A，然后用A的权重初始化后面深层网络前4个卷积层和最后3个全连接层，其他层从高斯分布中随机初始化。在paper submission后发现，直接采用[Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a.html)中的初始化方法就可以，即**Xavier方法**。
- paper中评论，因为A-LRN中的**Local Response Normalisation(LRN)没有效果**，还增加了内存使用和计算量，所以后面的BCDE网络就不用了（微笑）。
- 在ILSVRC-2014 challenge中，VGG提交的是7模型融合结果，提交后他们测试2模型的融合结果要更好，top1 val好1%，top5 val好0.5%，不过是在multi-scale traing、multi-crop和dense一起加成下取得的结果。
- VGG (1 net, multi-crop & dense eval) 单网络比GoogLeNet单网络的性能要好约1%。
- 2014年，ImageNet竞赛Top5错误率首次进入0~10%区间。

以上。

# 参考

- [arXiv: Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)
- [Large Scale Visual Recognition Challenge 2014 (ILSVRC2014)](http://www.image-net.org/challenges/LSVRC/2014/results#clsloc)
- [Review: VGGNet — 1st Runner-Up (Image Classification), Winner (Localization) in ILSVRC 2014](https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11)