---
title: 深度学习的可解释性
mathjax: true
date: 2020-05-18 19:56:04
tags:
categories:
- 深度学习基础
---



博客：[博客园](https://www.cnblogs.com/shine-lee/) | [CSDN](https://blog.csdn.net/blogshinelee) | [blog](https://blog.shinelee.me/)



有些时候，仅仅知道模型做出来了什么判断是不够的，还希望知道模型为什么做出这样的判断。

可解释性，就是希望理解 或 在一定程度上理解 模型做出判断的理由。



# 写在前面

复杂度越高的模型越难以解释。

简单的线性模型 和 不高的决策树 可解释，如果特征维度过多 或者 大量的决策树构成了森林，可解释性也会



本文的讨论范围聚焦在计算机视觉领域，集中在CNN的可解释性上。



现阶段的可解释性尝试去回答







# 参考

- [utkuozbulak/pytorch-cnn-visualizations](https://github.com/utkuozbulak/pytorch-cnn-visualizations)
- [pytorch/captum](https://github.com/pytorch/captum)
- [Explainable AI](https://youtu.be/lnjrn3bF9lA) ([slide](http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2019/Lecture/XAI (v7).pdf))
- [More about Explainable AI](https://youtu.be/LsdiOt0wiWM) ([slide](https://docs.google.com/presentation/d/1oWsL_Yxp0P_l3OsiwMFOmVz02ZZJb86yYcndbUSL7Kc/edit?usp=sharing))
- 